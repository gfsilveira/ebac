{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Monte um passo a passo para o Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap\n",
    "\n",
    "Método de obtenção de datasets por amostragem com reposição de um dataset original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Treinamento dos modelos base learnings usando os diferentes datasets geradas pelo bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate\n",
    "\n",
    "Sumarização dos resultados obtidos nos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Explique com as suas palavras o Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap\n",
    "\n",
    "Bootstrap é um método de obtenção de datasets que são amostras de um dataset original. Um dataset será gerado com o mesmo número de instâncias do original. Cada uma dessas entradas desse novo dataset será obtida sorteando-se uma das instâncias originais. Em cada sorteio, todas as instâncias têm a mesma probabilidade de serem escolhidas, sendo portanto uma amostragem randômica com reposição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Cada uma das datasets será usada para a determinação de um modelo, por treinamento com esse dataset. Esses modelos são chamdos de base learnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate\n",
    "\n",
    "De cada modelo, será obtido os resultados de predição. \n",
    "\n",
    "- Caso seja um problema de classificação, o resultado será a classe que mais se repetil nas previsões realizadas pelos modelos.\n",
    "- Caso seja um problema de regressão, será usada a média aritmética dos valores obtidos pelas previsões dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Implementação em python do Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelagem\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059351</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.412055</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944962</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.443070</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.653520</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.181604</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.542496</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.294067</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.813139</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.571971</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  target\n",
       "0   0.059351        5.0   1.412055       31.0     1.0\n",
       "1   0.944962        7.0  -0.443070       75.0     0.0\n",
       "2   0.653520        2.0   0.181604       11.0     1.0\n",
       "3   0.542496        7.0  -0.294067       67.0     0.0\n",
       "4   0.813139        2.0  -0.571971       92.0     1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciamento do dataset original dontendo dados randômicos\n",
    "num_instancias = 100\n",
    "data = {\n",
    "    \"feature_1\": np.random.rand(num_instancias),\n",
    "    \"feature_2\": np.random.randint(1, 10, num_instancias),\n",
    "    \"feature_3\": np.random.randn(1, num_instancias)[0],\n",
    "    \"feature_4\": np.random.randint(10, 100, num_instancias),\n",
    "    \"target\": np.random.randint(0, 2, num_instancias),\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.astype(\"float64\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature_1  100 non-null    float64\n",
      " 1   feature_2  100 non-null    float64\n",
      " 2   feature_3  100 non-null    float64\n",
      " 3   feature_4  100 non-null    float64\n",
      " 4   target     100 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 4.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Verificando as variáveis do dataset original\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Função que recebe o dataset original e retorna um novo por bootstrap\n",
    "    :param dataset (pd.DataFrame): Original\n",
    "    :return new_dataset (pd.DataFrame): Bootstrap\n",
    "    '''\n",
    "    dataset = df.copy()\n",
    "    new_dataset = pd.DataFrame(columns=dataset.columns)\n",
    "    sample_enter = dataset.sample(1)\n",
    "\n",
    "    for _ in range(len(dataset)):\n",
    "        new_dataset = pd.concat((new_dataset, sample_enter))\n",
    "        sample_enter = dataset.sample(1)\n",
    "    new_dataset = new_dataset.astype(\"float64\")\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Sem index comum\n",
      "Index comum: 70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciando uma lista contendo todos os datasets obtidos por bootstrap\n",
    "\n",
    "# Serão obtidos 20 datasets\n",
    "entradas = 20\n",
    "\n",
    "# Index para os datasets\n",
    "set_teste = {i for i in range(entradas)}\n",
    "\n",
    "c = True\n",
    "while c:\n",
    "\n",
    "    # Instanciando uma lista com os datasets\n",
    "    df_bootstrap = [bootstrap(df) for _ in range(entradas)]\n",
    "\n",
    "    # Instancia um array com os index contidos em cada um dos datasets\n",
    "    df_index = np.array([list(df_bootstrap[df_test].index) for df_test in range(entradas)])\n",
    "    try:\n",
    "\n",
    "        # Verifica se o index do dataset padrão está presente em cada um dos datset obtidos por bootstrap\n",
    "        save_index = [i for i in df.index.values if set(np.where(df_index == i)[0]) == set_teste][0]\n",
    "\n",
    "        # Caso o index esteja presente em todos, encerra o while\n",
    "        c = False\n",
    "        print(f\"Index comum: {save_index}\")\n",
    "    except:\n",
    "        print(\"Sem index comum\")\n",
    "\n",
    "save_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>target</td>      <th>  No. Observations:  </th>  <td>   100</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    95</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 28 Jun 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.03225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>13:12:33</td>     <th>  Log-Likelihood:    </th> <td> -67.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -69.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.3466</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.0331</td> <td>    0.831</td> <td>   -0.040</td> <td> 0.968</td> <td>   -1.661</td> <td>    1.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>feature_1</th> <td>    0.2967</td> <td>    0.712</td> <td>    0.417</td> <td> 0.677</td> <td>   -1.100</td> <td>    1.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>feature_2</th> <td>   -0.1301</td> <td>    0.091</td> <td>   -1.433</td> <td> 0.152</td> <td>   -0.308</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>feature_3</th> <td>    0.1847</td> <td>    0.241</td> <td>    0.767</td> <td> 0.443</td> <td>   -0.288</td> <td>    0.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>feature_4</th> <td>    0.0081</td> <td>    0.009</td> <td>    0.922</td> <td> 0.356</td> <td>   -0.009</td> <td>    0.025</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &      target      & \\textbf{  No. Observations:  } &      100    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &       95    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &        4    \\\\\n",
       "\\textbf{Date:}            & Fri, 28 Jun 2024 & \\textbf{  Pseudo R-squ.:     } &  0.03225    \\\\\n",
       "\\textbf{Time:}            &     13:12:33     & \\textbf{  Log-Likelihood:    } &   -67.002   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -69.235   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } &   0.3466    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                    & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}  &      -0.0331  &        0.831     &    -0.040  &         0.968        &       -1.661    &        1.595     \\\\\n",
       "\\textbf{feature\\_1} &       0.2967  &        0.712     &     0.417  &         0.677        &       -1.100    &        1.693     \\\\\n",
       "\\textbf{feature\\_2} &      -0.1301  &        0.091     &    -1.433  &         0.152        &       -0.308    &        0.048     \\\\\n",
       "\\textbf{feature\\_3} &       0.1847  &        0.241     &     0.767  &         0.443        &       -0.288    &        0.657     \\\\\n",
       "\\textbf{feature\\_4} &       0.0081  &        0.009     &     0.922  &         0.356        &       -0.009    &        0.025     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   No. Observations:                  100\n",
       "Model:                          Logit   Df Residuals:                       95\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Fri, 28 Jun 2024   Pseudo R-squ.:                 0.03225\n",
       "Time:                        13:12:33   Log-Likelihood:                -67.002\n",
       "converged:                       True   LL-Null:                       -69.235\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.3466\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.0331      0.831     -0.040      0.968      -1.661       1.595\n",
       "feature_1      0.2967      0.712      0.417      0.677      -1.100       1.693\n",
       "feature_2     -0.1301      0.091     -1.433      0.152      -0.308       0.048\n",
       "feature_3      0.1847      0.241      0.767      0.443      -0.288       0.657\n",
       "feature_4      0.0081      0.009      0.922      0.356      -0.009       0.025\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determinação do modelo de regressão logistica usando o primeiro dataset obtido por bootstrap\n",
    "modelo = \"target ~ feature_1 + feature_2 + feature_3 + feature_4\"\n",
    "\n",
    "reglog = smf.logit(\n",
    "    modelo,\n",
    "    data=df_bootstrap[0]\n",
    ").fit(method='bfgs')\n",
    "\n",
    "reglog.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.362618</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.967787</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_1  feature_2  feature_3  feature_4  target  pred\n",
       "70   0.362618        2.0  -0.967787       68.0     0.0   1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Faz a predição do target e comparar com o dado original\n",
    "pred = reglog.predict(df.loc[save_index, :])\n",
    "df['pred'] = (pred > 0.5).astype(\"int64\")\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_learnings(df_train: pd.DataFrame, save_index: int) -> dict:\n",
    "    '''\n",
    "    Função de obtenção dos Base learnings.\n",
    "    Recebe uma DataFrame e determina a predição do target em uma instância específica\n",
    "    :param df_trains (pd.DataFrame): Dataset para ser usado no treinamento\n",
    "    :return (int): Dicionário com a predição dos valores obtidos no treinamento\n",
    "    '''\n",
    "    modelo = \"target ~ feature_1 + feature_2 + feature_3 + feature_4\"\n",
    "    reg = smf.logit(\n",
    "        modelo,\n",
    "        data=df_train\n",
    "    ).fit(method='bfgs').predict(df_train.loc[save_index, :])\n",
    "\n",
    "    retorno = {\n",
    "        \"index\": pred.index[0],\n",
    "        \"valor\": pred.values[0],\n",
    "        \"target_bool\": pred.values[0] > 0.5,\n",
    "        \"target_float\": float(pred.values[0] > 0.5),\n",
    "    }\n",
    "\n",
    "    return retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'index': 70,\n",
       " 'valor': 0.545935516977216,\n",
       " 'target_bool': True,\n",
       " 'target_float': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testando a função de predição em um dataset bootstrap\n",
    "base_learnings(df_train=df_bootstrap[0], save_index=save_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.627919\n",
      "         Iterations: 22\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578966\n",
      "         Iterations: 21\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.644088\n",
      "         Iterations: 23\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 26\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.646748\n",
      "         Iterations: 23\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 26\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.606163\n",
      "         Iterations: 24\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657513\n",
      "         Iterations: 21\n",
      "         Function evaluations: 24\n",
      "         Gradient evaluations: 24\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.663028\n",
      "         Iterations: 22\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 26\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.654523\n",
      "         Iterations: 23\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.628143\n",
      "         Iterations: 24\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.614208\n",
      "         Iterations: 23\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.632989\n",
      "         Iterations: 22\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.613246\n",
      "         Iterations: 25\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588948\n",
      "         Iterations: 25\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.663001\n",
      "         Iterations: 21\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.651409\n",
      "         Iterations: 22\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.652606\n",
      "         Iterations: 22\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.663275\n",
      "         Iterations: 22\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.666047\n",
      "         Iterations: 22\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 26\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.648254\n",
      "         Iterations: 24\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testando a função de predição em todos os datasets bootstrap\n",
    "aggregat_list = [base_learnings(df_train=df, save_index=save_index)[\"target_float\"] for df in df_bootstrap]\n",
    "aggregat_list = np.array(aggregat_list)\n",
    "aggregat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Compara os valores obtidos e retorna o mais frequente pelo método de agregação \n",
    "num_zeros = (np.array(aggregat_list) == 0.0).sum()\n",
    "num_ones = (np.array(aggregat_list) != 0.0).sum()\n",
    "if num_zeros > num_ones:\n",
    "    aggregat = 0.0\n",
    "    print(f\"Aggregation = {aggregat}\")\n",
    "else:\n",
    "    aggregat = 1.0\n",
    "    print(f\"Aggregation = {aggregat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ebac_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
